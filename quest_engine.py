import json
import logging
from typing import Dict, List, Optional, Any
from openai import OpenAI
from config import OPENROUTER_API_KEY, OPENROUTER_BASE_URL, MODEL_NAME

logger = logging.getLogger(__name__)

class QuestEngine:
    def __init__(self):
        # Initialize with real API configuration using OpenAI client
        self.client = OpenAI(
            api_key=OPENROUTER_API_KEY,
            base_url=OPENROUTER_BASE_URL
        )
        self.model_name = MODEL_NAME
        
    async def generate_quest(self, requirements: str) -> Optional[Dict[str, Any]]:
        """
        Generate a quest scenario using LLM based on user requirements.
        This uses the OpenRouter API with qwen/qwen3-4b:free model.
        """
        try:
            # Prepare the prompt for generating quest
            prompt = f"""
            –°–æ–∑–¥–∞–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–≤–µ—Å—Ç –¥–ª—è –¥–µ—Ç–µ–π (–≤–æ–∑—Ä–∞—Å—Ç 5-7 –ª–µ—Ç) –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π:

            {requirements}

            –ö–≤–µ—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å:
            - –ü—Ä–æ—Å—Ç—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–µ—Ç–µ–π
            - –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º, –Ω–æ –≤–µ—Å–µ–ª—ã–º
            - –°–æ–¥–µ—Ä–∂–∞—Ç—å 3-5 –æ—Å–Ω–æ–≤–Ω—ã—Ö —à–∞–≥–æ–≤ —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –≤—ã–±–æ—Ä–∞
            - –ò–º–µ—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –æ–±—Ä–∞–∑—ã (–∂–∏–≤–æ—Ç–Ω—ã–µ, –º–∞–≥–∏—è, –ø—Ä–∏—Ä–æ–¥–∞)
            - –í–∫–ª—é—á–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–Ω—Ü–æ–≤–æ–∫

            –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:
            {{
                "quest": {{
                    "title": "–ù–∞–∑–≤–∞–Ω–∏–µ –∫–≤–µ—Å—Ç–∞",
                    "startStepId": "step_1",
                    "steps": [
                        {{
                            "id": "step_1",
                            "image": "–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —à–∞–≥–∞",
                            "text": "–¢–µ–∫—Å—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è —à–∞–≥–∞",
                            "options": [
                                {{
                                    "text": "–í–∞—Ä–∏–∞–Ω—Ç –≤—ã–±–æ—Ä–∞ 1",
                                    "nextStepId": "step_2a",
                                    "emoji": "üòÄ"
                                }}
                            ]
                        }}
                    ]
                }}
            }}

            –í–∞–∂–Ω–æ:
            - –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
            - –°–¥–µ–ª–∞–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–º –¥–ª—è –¥–µ—Ç–µ–π
            - –ö–∞–∂–¥—ã–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –≤—ã–±–æ—Ä–∞
            - –ö–æ–Ω—Ü–æ–≤–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º–∏ –∏ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–º–∏
            """

            # Make the API call using OpenAI client
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2048
            )
            
            # Extract the generated quest from the response
            try:
                content = response.choices[0].message.content
                if content is None:
                    logger.error("API response content is None")
                    return None
                quest_data = json.loads(content)
                return quest_data
            except (json.JSONDecodeError, KeyError) as e:
                logger.error(f"Failed to parse API response: {str(e)}")
                # Try to extract JSON from markdown if it's wrapped in code blocks
                content = response.choices[0].message.content
                if content is None:
                    return None
                try:
                    start = content.find('{')
                    end = content.rfind('}') + 1
                    if start != -1 and end != -1:
                        json_str = content[start:end]
                        quest_data = json.loads(json_str)
                        return quest_data
                except Exception as parse_error:
                    logger.error(f"Failed to extract JSON from response: {str(parse_error)}")
                    return None

        except Exception as e:
            logger.error(f"Error generating quest: {str(e)}")
            return None
    
    async def process_choice(self, current_step: Dict[str, Any], user_choice: str, all_steps: List[Dict]) -> Optional[str]:
        """
        Process user's choice and find the best matching option using LLM.
        Uses OpenRouter API to determine the most appropriate next step.
        """
        try:
            # Prepare prompt for matching user choice with options
            options_text = "\n".join([f"{i+1}. {opt['text']}" for i, opt in enumerate(current_step.get('options', []))])
            
            prompt = f"""
            –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª: "{user_choice}"
            
            –¢–µ–∫—É—â–∏–π —à–∞–≥:
            {current_step.get('text', '–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞')}
            
            –í–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–±–æ—Ä–∞:
            {options_text}
            
            –û–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –≤—ã–±–æ—Ä–∞ –Ω–∞–∏–±–æ–ª–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Ç–≤–µ—Ç—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
            –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ ID —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "step_2a" –∏–ª–∏ "ending_1").
            –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, –≤–µ—Ä–Ω–∏ "None".
            """

            # Make the API call using OpenAI client
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100
            )

            # Extract the result from the response
            try:
                content = response.choices[0].message.content
                if content is None:
                    logger.error("API response content is None in process_choice")
                    return None
                    
                result = content.strip().lower()
                
                if "none" in result or "–Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç" in result or "–Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç" in result:
                    return None
                    
                # Look for matching step ID in options
                for option in current_step.get('options', []):
                    if user_choice.lower() in option['text'].lower():
                        return option['nextStepId']
                        
                # If no direct match, try to find the best match based on content
                for option in current_step.get('options', []):
                    if any(word in user_choice.lower() for word in option['text'].lower().split()):
                        return option['nextStepId']
                
                return None
                
            except Exception as e:
                logger.error(f"Error parsing process_choice response: {str(e)}")
                return None

        except Exception as e:
            logger.error(f"Error processing choice: {str(e)}")
            return None
    
    async def create_new_branch(self, current_step: Dict[str, Any], user_choice: str, all_steps: List[Dict]) -> Optional[Dict]:
        """
        Create a new branch in the quest when no suitable option is found.
        Uses OpenRouter API to generate appropriate content for the new step.
        """
        try:
            # Prepare prompt for creating new branch
            prompt = f"""
            –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª: "{user_choice}"
            
            –¢–µ–∫—É—â–∏–π —à–∞–≥:
            {current_step.get('text', '–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞')}
            
            –°–æ–∑–¥–∞–π –Ω–æ–≤—ã–π —à–∞–≥ –∫–≤–µ—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—ã–±–æ—Ä—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
            –®–∞–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–æ–≥–∏—á–Ω—ã–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç—å 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –≤—ã–±–æ—Ä–∞.
            
            –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:
            {{
                "id": "step_new_1",
                "image": "–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤–æ–≥–æ —à–∞–≥–∞",
                "text": "–¢–µ–∫—Å—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è –Ω–æ–≤–æ–≥–æ —à–∞–≥–∞",
                "options": [
                    {{
                        "text": "–í–∞—Ä–∏–∞–Ω—Ç –≤—ã–±–æ—Ä–∞ 1",
                        "nextStepId": "step_new_2a",
                        "emoji": "üòÄ"
                    }}
                ]
            }}

            –í–∞–∂–Ω–æ:
            - –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
            - –°–¥–µ–ª–∞–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –º–æ—Ç–∏–≤–∏—Ä—É—é—â–∏–º –¥–ª—è –¥–µ—Ç–µ–π
            - –ö–∞–∂–¥—ã–π —à–∞–≥ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –≤—ã–±–æ—Ä–∞
            """

            # Make the API call using OpenAI client
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1024
            )

            # Extract the generated step from the response
            try:
                content = response.choices[0].message.content
                if content is None:
                    logger.error("API response content is None in create_new_branch")
                    return None
                new_step_data = json.loads(content)
                return new_step_data
            except (json.JSONDecodeError, KeyError) as e:
                logger.error(f"Failed to parse create_new_branch API response: {str(e)}")
                # Try to extract JSON from markdown if it's wrapped in code blocks
                content = response.choices[0].message.content
                if content is None:
                    return None
                try:
                    start = content.find('{')
                    end = content.rfind('}') + 1
                    if start != -1 and end != -1:
                        json_str = content[start:end]
                        new_step_data = json.loads(json_str)
                        return new_step_data
                except Exception as parse_error:
                    logger.error(f"Failed to extract JSON from create_new_branch response: {str(parse_error)}")
                    return None

        except Exception as e:
            logger.error(f"Error creating new branch: {str(e)}")
            return None